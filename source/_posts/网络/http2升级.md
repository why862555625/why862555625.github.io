---
title: http2升级
tags:
  - 网络

categories: 网络
keywords: 'http2升级'
description: http2升级
top_img: 设置false不显示顶部图片
sticky: 数值越大越靠前
cover: 首页封面
comments: false评论
abbrlink: d9795d88
date: 2023-10-07 14:48:54
updated: 2023-10-07 14:48:54
---



![image-20231008102528048](https://raw.githubusercontent.com/why862555625/images/main/image-20231008102528048.png)

<!-- more -->

# 问题描述

**使用http1时的情况：**

假设我们有36个请求需要发送（真实情况160+），由于浏览器的tcp链接限制，最多只能建立6个链接。也就是一次只能发送6个请求，那剩下的30个请求都需要在请求队列中等待。如果这6个请求都是较为耗时的任务（资源大，server处理耗时较长等），那请求队列中的请求等待时间会进一步加长。（项目中累计队列等待时间约为9秒）

![6](https://raw.githubusercontent.com/why862555625/images/main/image-20231007153433034.png)

**使用http2时的情况：**

使用http2会对tcp链接进行复用，可以通过一个tcp链接同时发送多个请求。并且可以通过 请求头`weight`、 `depends-on`、`X-Priority`等字段确定优先级，让服务器根据请求头来调整处理顺序。

![image-20231007155045429](https://raw.githubusercontent.com/why862555625/images/main/image-20231007155045429.png)

> http2优势：
>
> 1. **多路复用（Multiplexing）**：HTTP/2 支持在同一个连接上同时传输多个请求和响应。这样，多个请求可以并行处理，不需要等待之前的请求响应完成，大幅提高了页面加载速度。
> 2. **头部压缩（Header Compression）**：HTTP/2 使用 HPACK 算法对头部信息进行压缩，减小了数据包的大小，降低了网络传输的延迟。这种压缩机制减少了带宽的使用，尤其对于大型网页或者请求头很大的场景效果显著。
> 3. **二进制分帧（Binary Framing）**：HTTP/2 将所有的传输信息分割为更小的帧（Frames），并且每个帧都被赋予一个唯一的标识符，这种二进制分帧的机制使得协议更加高效，也更容易实现。
> 4. **服务器推送（Server Push）**：HTTP/2 允许服务器在客户端请求之前将额外的响应数据推送给客户端，提高了页面加载的速度。这种特性可以避免客户端发送了一个请求后，服务器又返回一个推送的资源。
> 5. **优先级（Priority）**：HTTP/2 允许客户端为每个请求设置优先级，确保关键资源首先被传输，提高了页面的渲染速度和用户体验。
> 6. **流量控制（Flow Control）**：HTTP/2 支持流量控制，可以防止高速的生产者压倒了较慢的消费者，确保了资源的合理利用。
> 7. **支持请求和响应的取消（Request and Response Cancellation）**：HTTP/2 允许取消不需要的请求和响应，提高了灵活性和效率。

# 计算机网络基本知识

##  经典的网络7层协议

![img](https://raw.githubusercontent.com/why862555625/images/main/MBXY-CR-f2718999645d536b524ca3aaefb9de86.png)



## **数据传输过程**



![image-20231007150948424](https://raw.githubusercontent.com/why862555625/images/main/image-20231007150948424.png)



**（1）应用层传输过程（将其他信息翻译成二进制数据）**

在应用层，数据被"翻译"为网络世界使用的语言——二进制编码数据。大家可以试想一下，人们需要通过计算机传输的数据形式千变万化、各式各样，有字母、数字汉字、图片、声音等。这些信息对于单纯通过弱电流传输的计算机来说太过于"复杂"，因此这些方便人类识别的信息被应用层通过各种特殊的编码过程转换成二进制数据。这就是上面所描述的"翻译"过程，也是应用层在网络数据传输过程中最为核心的贡献。

**（2）传输层传输过程（分割：避免出错代价；标识应用层端口：找到对应应用）**

在传输层，上层数据被分割成小的数据段，并为每个分段后的数据封装TCP报文头部。应用层将人们需要传输的信息转换成计算机能够识别的二进制数据后，这些数据往往都是海量的。例如，一张高清晰的图片转换成二进制数据可能会有几百万甚至几千万位比特，一次性传输如此庞大的数据，一旦网络出现问题而导致数据出错就要重新传输，数据量过大也会增加出错的概率，最终可能导致网络资源耗尽。因此，将数据先分割成小段再逐段传输，一旦数据传输出现错误只需重传这一小段数据即可。

在TCP头部有一个关键的字段信息——端口号，它用于标识上层的协议或应用程序，确保上层应用数据的正常通信。计算机是可以多进程并发运行的，在通过QQ发送信息的同时也可以通过IE浏览Web页面。但是对于传输层而言，它是不可能"看懂"应用层传输数据的具体内容的，因此只能借助一种标识来确定接收到的数据对应的应用程序，这种标识就是端口号。

**（3）网络层传输过程（寻址ip,标识自己ip）**

在网络层，上层数据被封装上新的报文头部——IP头部。值得注意的是，这里所说的上层数据包括TCP头部，也就是说，这里的上层是指传输层。对于网络层而言，它是"看不懂"TCP包头中的内容的，无论是应用层的应用数据，还是TCP头部信息都属于上层数据。　　　　

在IP头部中有一个关键的字段信息——IP地址，它是由一组32位的二进制数组成的，用于标识网络的逻辑地址。回想刚才寄信的例子，我们在信封上填写了对方的详细地址和本地的详细地址，以保证收件人能够顺利收到信件。网络层的传输过程与其类似，在IP头部中包含目标IP地址和源IP地址，在网络传输过程中的一些中间设备，如路由器，会根据目标IP地址来进行逻辑寻址，找到正确的路径将数据转发到目的端主机。如果中间的路由设备发现目标的IP地址是不可能到达的，它将会把该消息传回发送端主机，因此在网络层需要同时封装目标 IP和源IP。

**（4）数据链路层传输过程（标识唯一主机）**

在数据链路层，上层数据被封装一个MAC头部，其内部有一个关键的字段信息——MAC地址，它由一组48位的二进制数组成。在目前阶段，我们可以先把它理解为固化在硬件设备中的物理地址，具有全球唯一性。例如，之前讲解的网卡就有属于自己的唯一的MAC地址。和IP头部类似，在MAC头部也同时封装着目标MAC地址和源MAC 地址。

**（5）物理层传输过程（转换成好传输的介质）**

无论在之前封装的报文头部还是上层的数据信息都是由二进制数组成的，在物理层，将这些二进制数字组成的比特流转换成电信号在网络中传输。



## TCP链接建立过程

![img](https://raw.githubusercontent.com/why862555625/images/main/dev-network-tcpip-4.jpg)



> 一般来说，SYN报文的格式如下：
>
> - 源端口号：用于标识发送方的端口号。
> - 目标端口号：用于标识接收方的端口号。
> - 序列号（Sequence Number）：用于标识报文的顺序，SYN报文中的序列号表示数据起始位置。
> - 确认号（Acknowledgment Number）：用于确认已经收到的数据，SYN报文中的确认号表示期望收到的下一个数据的位置。
> - 数据偏移和保留位（Data Offset and Reserved）：用于指示TCP头部的长度和保留字段，通常为20字节。
> - 标志位（Flags）：用于标识TCP报文的类型和属性，SYN报文中的SYN标志被置为1。
> - 窗口大小（Window Size）：用于指示发送方的接收窗口大小。
> - 校验和（Checksum）：用于校验TCP头部和数据的完整性。
> - 紧急指针（Urgent Pointer）：用于指示紧急数据的末尾位置。
> - 选项（Options）：可选字段，包含TCP的一些额外信息。

**为什么要四次挥手：因为可能还有数据没有发完。**



### TCP协议的慢启动

> TCP慢启动（Slow Start）是一种TCP拥塞控制算法，用于在TCP连接刚刚建立或者在拥塞发生后进行连接恢复时，逐渐增加发送窗口大小，以有效地利用网络带宽并避免拥塞引起的数据丢失。
>
> 当一个TCP连接建立时，初始时发送窗口大小（即允许发送的数据量）会被设置为一个较小的值，以避免在网络刚开始使用时可能出现的拥塞。具体而言，TCP慢启动的机制如下：
>
> 1. **初始拥塞窗口（Congestion Window）：** 在TCP连接刚建立时，初始拥塞窗口被设置为一个较小的值，通常为1个或几个段（Segment）的大小。这是为了避免在网络刚开始使用时就发送大量数据，可能引发拥塞。
> 2. **指数增长：** 在慢启动阶段，每次接收到一个确认（ACK）时，发送方的拥塞窗口会指数增长。具体地说，拥塞窗口的大小会加倍。例如，如果初始拥塞窗口为1个段，每次接收到一个确认后，窗口大小会变成2，然后4，8，依此类推。这种指数增长的方式使得发送方可以逐渐增加发送的数据量。
> 3. **拥塞窗口的调整：** 当拥塞窗口达到一个阈值（通常由网络延迟和带宽决定）或者检测到网络拥塞时，TCP发送方会转入拥塞避免（Congestion Avoidance）阶段，此时拥塞窗口的增长将变得线性而不再是指数增长。
>
> TCP慢启动的目的是在网络刚开始使用时，逐渐增加发送窗口，测试网络的容量，确保不会引发拥塞。一旦连接稳定，TCP的拥塞窗口逐渐增大，以更好地利用可用带宽，提高数据传输效率。



**为什么会慢启动**



> 发送大的窗口在高带宽高延迟网络环境中可以提高数据传输的效率，但如果不合理地设置，可能导致网络拥塞，引发一系列问题。网络拥塞通常发生在网络容量无法满足当前数据传输需求的情况下。以下是发送大的窗口可能引发的问题：
>
> 1. **数据包丢失：** 在网络拥塞时，路由器或交换机可能会丢弃数据包，导致数据传输中断或者丢失部分数据。这会引发需要重新传输数据的情况，增加了网络的负担。
> 2. **队头阻塞：** 在网络拥塞时，数据包可能会在网络中形成堆积，这种情况被称为队头阻塞。这会导致后续的数据包等待在队列中，延迟传输，影响了实时性要求高的应用，如在线游戏、语音通话等。
> 3. **延迟增加：** 网络拥塞会导致数据包在网络中的传输延迟增加。当发送方没有及时收到确认信息时，它会认为数据包丢失，触发重传机制，这会引起更大的延迟。
> 4. **吞吐量下降：** 当网络拥塞发生时，各个连接之间的竞争增加，导致每个连接的吞吐量减少。这意味着网络上的所有数据传输都变慢，影响用户体验。
> 5. **不公平性：** 在网络拥塞时，可能会出现不公平性，即某些连接的数据传输速度较快，而其他连接的数据传输速度较慢。这可能会导致某些用户或应用受到不公平待遇。



# http协议

超文本传输协议（HTTP）用于通过超文本链接加载网页。HTTP是应用层协议的一种，在联网设备之间传输信息，并在网络协议堆栈的其他层之上运行。HTTP是基于TCP / IP的通信协议，默认端口是TCP 80，但也可以使用其他端口。

## 1. 基本特性

HTTP 协议基本特性：

- **HTTP 是无连接的：** HTTP客户端，即浏览器发出请求后，客户端等待响应。服务器处理该请求并发送回响应，然后客户端断开连接。客户端和服务器仅在当次请求中互相了解，至于上一次是否有连接或者连接的信息是无从得知的。
- **HTTP是独立于媒体的：** 这意味着，只要客户端和服务器都知道如何处理数据内容，任何类型的数据都可以通过HTTP发送。客户端和服务器都需要使用适当的 MIME(多用途互联网邮件扩展) 类型 指定内容类型。
- **HTTP是无状态的：** 如上所述，HTTP 是无连接的，这是 HTTP 是无状态协议的直接结果。服务器和客户端仅在当前请求期间彼此知道，之后他们俩彼此忘记。由于协议的这种性质，客户端和浏览器都无法在整个网页的不同请求之间保留信息。

## 2. [http协议的发展过程](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP)

#### 万维网的发明

1989 年，当时在 CERN 工作的 Tim Berners-Lee 博士写了一份关于建立一个通过网络传输超文本系统的报告。这个系统起初被命名为 *Mesh*，在随后的 1990 年项目实施期间被更名为*万维网*（World Wide Web）。它在现有的 TCP 和 IP 协议基础之上建立，由四个部分组成：

- 一个用来表示超文本文档的文本格式，*[超文本标记语言](https://developer.mozilla.org/zh-CN/docs/Web/HTML)*（HTML）。
- 一个用来交换超文本文档的简单协议，超文本传输协议（HTTP）。
- 一个显示（以及编辑）超文本文档的客户端，即网络浏览器。第一个网络浏览器被称为 *WorldWideWeb。*
- 一个服务器用于提供可访问的文档，即 *httpd* 的前身。

这四个部分完成于 1990 年底，且第一批服务器已经在 1991 年初在 CERN 以外的地方运行了。1991 年 8 月 16 日，Tim Berners-Lee 在公开的超文本新闻组上[发表](https://www.w3.org/People/Berners-Lee/1991/08/art-6484.txt)的文章被视为是万维网公共项目的开始。

HTTP 在应用的早期阶段非常简单，后来被称为 HTTP/0.9，有时也叫做单行（one-line）协议。

#### [HTTP/0.9——单行协议](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP#http0.9——单行协议)

最初版本的 HTTP 协议并没有版本号，后来它的版本号被定位在 0.9 以区分后来的版本。HTTP/0.9 极其简单：请求由单行指令构成，以唯一可用方法 [`GET`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/GET) 开头，其后跟目标资源的路径（一旦连接到服务器，协议、服务器、端口号这些都不是必须的）。

```
GET /mypage.html
```

响应也极其简单的：只包含响应文档本身。

```
<html>
  这是一个非常简单的 HTML 页面
</html>
```

跟后来的版本不同，HTTP/0.9 的响应内容并不包含 HTTP 头。这意味着只有 HTML 文件可以传送，无法传输其他类型的文件。也没有状态码或错误代码。一旦出现问题，一个特殊的包含问题描述信息的 HTML 文件将被发回，供人们查看。

#### [HTTP/1.0——构建可扩展性](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP#http1.0——构建可扩展性)

由于 HTTP/0.9 协议的应用十分有限，浏览器和服务器迅速扩展内容使其用途更广：

- 协议版本信息现在会随着每个请求发送（`HTTP/1.0` 被追加到了 `GET` 行）。
- 状态码会在响应开始时发送，使浏览器能了解请求执行成功或失败，并相应调整行为（如更新或使用本地缓存）。
- 引入了 HTTP 标头的概念，无论是对于请求还是响应，允许传输元数据，使协议变得非常灵活，更具扩展性。
- 在新 HTTP 标头的帮助下，具备了传输除纯文本 HTML 文件以外其他类型文档的能力（凭借 [`Content-Type`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type) 标头）。

#### [HTTP/1.1——标准化的协议](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP#http1.1——标准化的协议)

HTTP/1.1 消除了大量歧义内容并引入了多项改进：

- 连接可以复用，节省了多次打开 TCP 连接加载网页文档资源的时间。
- 支持响应分块。
- 引入额外的缓存控制机制。
- 引入内容协商机制，包括语言、编码、类型等。并允许客户端和服务器之间约定以最合适的内容进行交换。
- 凭借 [`Host`](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Host) 标头，能够使不同域名配置在同一个 IP 地址的服务器上。

#### [HTTP/2——为了更优异的表现](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP#http2——为了更优异的表现)

这些年来，网页愈渐变得的复杂，甚至演变成了独有的应用，可见媒体的播放量，增进交互的脚本大小也增加了许多：更多的数据通过 HTTP 请求被传输。HTTP/1.1 链接需要请求以正确的顺序发送，理论上可以用一些并行的链接（尤其是 5 到 8 个），带来的成本和复杂性堪忧。比如，HTTP 管线化（pipelining）就成为了 Web 开发的负担。为此，在 2010 年早期，谷歌通过实践了一个实验性的 SPDY 协议。这种在客户端和服务器端交换数据的替代方案引起了在浏览器和服务器上工作的开发人员的兴趣。明确了响应数量的增加和解决复杂的数据传输，SPDY 成为了 HTTP/2 协议的基础。

HTTP/2 在 HTTP/1.1 有几处基本的不同：

- HTTP/2 是二进制协议而不是文本协议。不再可读，也不可无障碍的手动创建，改善的优化技术现在可被实施。
- 这是一个多路复用协议。并行的请求能在同一个链接中处理，移除了 HTTP/1.x 中顺序和阻塞的约束。
- 压缩了标头。因为标头在一系列请求中常常是相似的，其移除了重复和传输重复数据的成本。
- 其允许服务器在客户端缓存中填充数据，通过一个叫服务器推送的机制来提前请求。

在 2015 年 5 月正式标准化后，HTTP/2 取得了极大的成功，在 2022 年 1 月达到峰值，占所有网站的 46.9%（见[这些统计数据](https://w3techs.com/technologies/details/ce-http2)）。高流量的站点最迅速的普及，在数据传输上节省了可观的成本和支出。

这种迅速的普及率很可能是因为 HTTP2 不需要站点和应用做出改变：使用 HTTP/1.1 和 HTTP/2 对他们来说是透明的。拥有一个最新的服务器和新点的浏览器进行交互就足够了。只有一小部分群体需要做出改变，而且随着陈旧的浏览器和服务器的更新，而不需 Web 开发者做什么，用的人自然就增加了。

## 3. 协议头

**协议头的重要性（协议头的大小通常在几K到数十K之间）：**

> HTTP协议头具有以下几个重要的作用：
>
> 1. **传递元数据：** 协议头中可以包含各种元数据，如数据类型、字符编码、内容长度、响应状态等。这些信息有助于客户端和服务器了解所传输数据的特性，以正确地解析和处理数据。
> 2. **控制缓存和缓存策略：** 协议头中的Cache-Control、Expires等字段可以指示浏览器或代理服务器如何缓存响应数据，以及缓存的有效期。这些信息有助于提高性能，减少不必要的网络请求。
> 3. **进行身份验证：** HTTP协议头中的Authorization字段允许客户端向服务器发送身份验证信息，例如用户名和密码，以便访问受保护的资源。
> 4. **处理请求方法：** 请求中的HTTP方法（GET、POST、PUT、DELETE等）通常通过HTTP头部中的请求行指定，告诉服务器客户端希望执行的操作。
> 5. **重定向：** 通过HTTP响应头的Location字段，服务器可以告知客户端进行重定向，将请求重定向到其他URL。
> 6. **传递Cookie信息：** HTTP请求头中的Cookie字段可以用于传递客户端的身份认证信息，服务器可以根据这些信息识别用户。
> 7. **提供安全性：** HTTP头部中的一些字段，例如Strict-Transport-Security（严格传输安全性策略）等，可以增强通信的安全性。

### 报文示例：

**请求头报文**（[常见请求头响应头](https://juejin.cn/post/6844903745004765198)）

![img](https://raw.githubusercontent.com/why862555625/images/main/20180926095056907)

**响应头报文**

![img](https://raw.githubusercontent.com/why862555625/images/main/20180926113041788)





## 



## 4. 详解HTTP2

> http2优势：
>
> 1. **多路复用（Multiplexing）**：HTTP/2 支持在同一个连接上同时传输多个请求和响应。这样，多个请求可以并行处理，不需要等待之前的请求响应完成，大幅提高了页面加载速度。
> 2. **头部压缩（Header Compression）**：HTTP/2 使用 HPACK 算法对头部信息进行压缩，减小了数据包的大小，降低了网络传输的延迟。这种压缩机制减少了带宽的使用，尤其对于大型网页或者请求头很大的场景效果显著。
> 3. **二进制分帧（Binary Framing）**：HTTP/2 将所有的传输信息分割为更小的帧（Frames），并且每个帧都被赋予一个唯一的标识符，这种二进制分帧的机制使得协议更加高效，也更容易实现。
> 4. **服务器推送（Server Push）**：HTTP/2 允许服务器在客户端请求之前将额外的响应数据推送给客户端，提高了页面加载的速度。这种特性可以避免客户端发送了一个请求后，服务器又返回一个推送的资源。
> 5. **优先级（Priority）**：HTTP/2 允许客户端为每个请求设置优先级，确保关键资源首先被传输，提高了页面的渲染速度和用户体验。
> 6. **流量控制（Flow Control）**：HTTP/2 支持流量控制，可以防止高速的生产者压倒了较慢的消费者，确保了资源的合理利用。
> 7. **支持请求和响应的取消（Request and Response Cancellation）**：HTTP/2 允许取消不需要的请求和响应，提高了灵活性和效率。

### 1、二进制分帧层 (Binary Framing Layer)

> 优点：
>
> 1. **更高的效率：** 二进制帧的结构更加紧凑，相比于文本协议更加高效。这减少了在网络上传输的数据量，特别是在带宽受限的情况下，可以提高传输速度。
> 2. **多路复用（Multiplexing）：** HTTP/2 支持多路复用，即可以在一个连接上同时传输多个请求和响应，而不需要按照顺序等待前一个请求的响应。这是通过在一个连接上使用二进制帧实现的，每个帧都被标识为属于哪个流（Stream），从而实现了并发传输，提高了网络利用率。
> 3. **头部压缩（Header Compression）：** HTTP/2 使用 HPACK 算法对请求和响应的头部进行压缩，减小了每个帧的头部大小，节省了带宽。因为二进制帧的结构更加紧凑，压缩后的数据传输效率更高。
> 4. **优先级和依赖关系（Priority and Dependency）：** HTTP/2 允许在帧中设置优先级和依赖关系，使得服务器和客户端可以更好地控制数据流的优先级，确保关键资源的优先传输。
> 5. **更好的错误处理：** HTTP/2 的二进制帧结构允许更细致地标识错误，例如在一个响应的头部中指定错误码，而不必等到整个响应体传输完毕才能得知错误



> 二进制帧更加紧凑的原因：
>
> 1. **固定长度的帧头：** 在 HTTP/2 中，帧头的长度是固定的，相比于 HTTP/1.x 的文本头部，这种结构更加简单，减少了额外的信息传输。每个帧的帧头固定占用9个字节（8字节的帧长度和1字节的帧类型），相较于 HTTP/1.x 的文本头部，这是一个很小的开销。
> 2. **二进制压缩：** HTTP/2 使用了 HPACK 算法对请求和响应的头部进行二进制压缩，将头部字段名和字段值映射为索引，用更小的二进制表示，减少了传输的数据量。这种二进制压缩的头部信息更加紧凑，节省了带宽。
> 3. **优先级和依赖关系：** HTTP/2 允许在帧中设置优先级和依赖关系，这样服务器和客户端可以更精细地控制数据流的传输顺序。这种信息也可以更紧凑地编码，避免了传输额外的文本信息。
> 4. **数据帧和头部帧分离：** 在 HTTP/2 中，请求和响应的数据（Data）和头部（Headers）被分开传输，每种类型的帧专注于传输特定类型的数据。这样的分离可以提高帧的结构紧凑性，因为每个帧只需要携带特定类型的信息。



##### 帧 - Frame（选读）

所有帧都是一个固定的 9 字节头部 (payload 之前) 跟一个指定长度的负载 (payload):

```
+-----------------------------------------------+
|                 Length (24)                   |
+---------------+---------------+---------------+
|   Type (8)    |   Flags (8)   |
+-+-------------+---------------+-------------------------------+
|R|                 Stream Identifier (31)                      |
+=+=============================================================+
|                   Frame Payload (0...)                      ...
+---------------------------------------------------------------+
```

> - `Length` 代表整个 frame 的长度，用一个 24 位无符号整数表示。除非接收者在 SETTINGS_MAX_FRAME_SIZE 设置了更大的值 (大小可以是 2^14(16384) 字节到 2^24-1(16777215) 字节之间的任意值)，否则数据长度不应超过 2^14(16384) 字节。头部的 9 字节不算在这个长度里
> - `Type` 定义 frame 的类型，用 8 bits 表示。帧类型决定了帧主体的格式和语义，如果 type 为 unknown 应该忽略或抛弃。
> - `Flags` 是为帧类型相关而预留的布尔标识。标识对于不同的帧类型赋予了不同的语义。如果该标识对于某种帧类型没有定义语义，则它必须被忽略且发送的时候应该赋值为 (0x0)
> - `R` 是一个保留的比特位。这个比特的语义没有定义，发送时它必须被设置为 (0x0), 接收时需要忽略。
> - [Stream Identifier](https://link.juejin.cn?target=https%3A%2F%2Fhttpwg.org%2Fspecs%2Frfc7540.html%23StreamIdentifiers) 用作流控制，用 31 位无符号整数表示。客户端建立的 sid 必须为奇数，服务端建立的 sid 必须为偶数，值 (0x0) 保留给与整个连接相关联的帧 (连接控制消息)，而不是单个流
> - `Frame Payload` 是主体内容，由帧类型决定

共分为十种类型的帧:

> - `HEADERS`: 报头帧 (type=0x1)，用来打开一个流或者携带一个首部块片段
> - `DATA`: 数据帧 (type=0x0)，装填主体信息，可以用一个或多个 DATA 帧来返回一个请求的响应主体
> - `PRIORITY`: 优先级帧 (type=0x2)，指定发送者建议的流优先级，可以在任何流状态下发送 PRIORITY 帧，包括空闲 (idle) 和关闭 (closed) 的流
> - `RST_STREAM`: 流终止帧 (type=0x3)，用来请求取消一个流，或者表示发生了一个错误，payload 带有一个 32 位无符号整数的错误码 ([Error Codes](https://link.juejin.cn?target=https%3A%2F%2Fhttpwg.org%2Fspecs%2Frfc7540.html%23ErrorCodes))，不能在处于空闲 (idle) 状态的流上发送 RST_STREAM 帧
> - `SETTINGS`: 设置帧 (type=0x4)，设置此 `连接` 的参数，作用于整个连接
> - `PUSH_PROMISE`: 推送帧 (type=0x5)，服务端推送，客户端可以返回一个 RST_STREAM 帧来选择拒绝推送的流
> - `PING`: PING 帧 (type=0x6)，判断一个空闲的连接是否仍然可用，也可以测量最小往返时间 (RTT)
> - `GOAWAY`: GOWAY 帧 (type=0x7)，用于发起关闭连接的请求，或者警示严重错误。GOAWAY 会停止接收新流，并且关闭连接前会处理完先前建立的流
> - `WINDOW_UPDATE`: 窗口更新帧 (type=0x8)，用于执行流量控制功能，可以作用在单独某个流上 (指定具体 Stream Identifier) 也可以作用整个连接 (Stream Identifier 为 0x0)，只有 DATA 帧受流量控制影响。初始化流量窗口后，发送多少负载，流量窗口就减少多少，如果流量窗口不足就无法发送，WINDOW_UPDATE 帧可以增加流量窗口大小
> - `CONTINUATION`: 延续帧 (type=0x9)，用于继续传送首部块片段序列



**DATA 帧格式**

```
 +---------------+
 |Pad Length? (8)|
 +---------------+-----------------------------------------------+
 |                            Data (*)                         ...
 +---------------------------------------------------------------+
 |                           Padding (*)                       ...
 +---------------------------------------------------------------+
```

> - `Pad Length`: ? 表示此字段的出现时有条件的，需要设置相应标识 (set flag)，指定 Padding 长度，存在则代表 PADDING flag 被设置
> - `Data`: 传递的数据，其长度上限等于帧的 payload 长度减去其他出现的字段长度
> - `Padding`: 填充字节，没有具体语义，发送时必须设为 0，作用是混淆报文长度，与 TLS 中 CBC 块加密类似

DATA 帧有如下标识 (flags):

> - END_STREAM: bit 0 设为 1 代表当前流的最后一帧
> - PADDED: bit 3 设为 1 代表存在 Padding



**HEADERS 帧格式**

```
+---------------+
 |Pad Length? (8)|
 +-+-------------+-----------------------------------------------+
 |E|                 Stream Dependency? (31)                     |
 +-+-------------+-----------------------------------------------+
 |  Weight? (8)  |
 +-+-------------+-----------------------------------------------+
 |                   Header Block Fragment (*)                 ...
 +---------------------------------------------------------------+
 |                           Padding (*)                       ...
 +---------------------------------------------------------------+
```

> - `Pad Length`: 指定 Padding 长度，存在则代表 PADDING flag 被设置
> - `E`: 一个比特位声明流的依赖性是否是排他的，存在则代表 PRIORITY flag 被设置
> - `Stream Dependency`: 指定一个 stream identifier，代表当前流所依赖的流的 id，存在则代表 PRIORITY flag 被设置
> - `Weight`: 一个无符号 8 为整数，代表当前流的优先级权重值 (1~256)，存在则代表 PRIORITY flag 被设置
> - `Header Block Fragment`: header 块片段
> - `Padding`: 填充字节，没有具体语义，作用与 DATA 的 Padding 一样，存在则代表 PADDING flag 被设置

HEADERS 帧有以下标识 (flags):

> - END_STREAM: bit 0 设为 1 代表当前 header 块是发送的最后一块，但是带有 END_STREAM 标识的 HEADERS 帧后面还可以跟 CONTINUATION 帧 (这里可以把 CONTINUATION 看作 HEADERS 的一部分)
> - END_HEADERS: bit 2 设为 1 代表 header 块结束
> - PADDED: bit 3 设为 1 代表 Pad 被设置，存在 Pad Length 和 Padding
> - PRIORITY: bit 5 设为 1 表示存在 Exclusive Flag (E), Stream Dependency, 和 Weight



### 2. Header 压缩 (HPACK)


HTTP/2 中的头部压缩是指使用 HPACK 算法对请求和响应的头部信息进行压缩，从而减小传输的数据量。在传统的 HTTP/1.x 中，每次请求和响应都要携带大量的头部信息，这些信息包括请求方法、URL、Cookie、User-Agent 等等。在 HTTP/1.x 中，这些头部信息通常是文本形式，相对繁琐，而且重复的信息较多。

HTTP/2 引入了头部压缩的机制，通过以下步骤来减小头部信息的传输量：

1. **索引（Indexing）：** HTTP/2 的头部压缩使用了索引的概念。在通信的双方维护一个头部字段表（Header Table），每个字段都有一个唯一的整数索引号（KEY,value,都在表中）。当发送方需要发送一个头部字段时，如果该字段在表中已经存在，发送的只是这个字段的索引号，而不是完整的字段名和字段值。接收方根据索引号在本地的表中查找对应的字段，从而还原出完整的头部信息。
2. **字面量和索引结合（Literal with Incremental Indexing）：** 如果头部字段不在表中，发送方可以选择将字段的字面量（Literal）和索引号同时发送给接收方，接收方将字段添加到本地的头部字段表中，以备将来的引用。
3. **去除冗余字段（Duplicate Fields Elimination）：** 在 HTTP/2 中，相同字段名的多个字段值可以合并成一个字段，这样就避免了重复传输相同字段名的问题。
4. **动态表大小调整（Dynamic Table Size Update）：** 头部字段表的大小是可以动态调整的。发送方可以通过发送特定帧（SETTINGS Frame）来通知接收方动态表的最大大小，接收方根据这个信息来调整本地的头部字段表大小。

通过以上机制，HTTP/2 的头部压缩有效地减小了头部信息的传输量，提高了性能。这种压缩机制在实际应用中，特别是对于带宽受限的移动网络环境，显著减少了请求和响应的传输时间，提高了页面加载速度和用户体验。

##### 

### 3. 多路复用 (MultiPlexing)（最重要：解决队列堵塞问题，提高网络利用率）

在一个 TCP 连接上，我们可以向对方不断发送帧，每帧的 stream identifier 的标明这一帧属于哪个流，然后在对方接收时，根据 stream identifier 拼接每个流的所有帧组成一整块数据。 把 HTTP/1.1 每个请求都当作一个流，那么多个请求变成多个流，请求响应数据分成多个帧，不同流中的帧交错地发送给对方，这就是 HTTP/2 中的多路复用。

#### 流 - Stream（选读）

流只是一个逻辑上的概念，代表 HTTP/2 连接中在客户端和服务器之间交换的独立双向帧序列，每个帧的 Stream Identifier 字段指明了它属于哪个流。

流有以下特性:

- 单个 h2 连接可以包含多个并发的流，两端之间可以交叉发送不同流的帧
- 流可以由客户端或服务器来单方面地建立和使用，或者共享
- 流可以由任一方关闭
- 帧在流上发送的顺序非常重要，最后接收方会把相同 Stream Identifier (同一个流) 的帧重新组装成完整消息报文

**流的状态**



![image](https://raw.githubusercontent.com/why862555625/images/main/1658dc4f199f3191%7Etplv-t2oaga2asx-jj-mark%3A3024%3A0%3A0%3A0%3Aq75.png)



> 注意图中的 send 和 recv 对象是指端点，不是指当前的流



**idle**

所有流以“空闲”状态开始。在这种状态下，没有任何帧的交换

其状态转换:

- 发送或者接收一个 HEADERS 帧会使空闲 `idle` 流变成打开 `open` 状态，其中 HEADERS 帧的 Stream Identifier 字段指明了流 id。同样的 HEADERS 帧(带有 END_STREAM )也可以使一个流立即进入 half-closed 状态。

- 服务端必须在一个打开 

  ```
  open
  ```

   或者半关闭 (远端) 

  ```
  half-closed(remote)
  ```

   状态的流 (由客户端发起的) 上发送 PUSH_PROMISE 帧，其中 PUSH_PROMISE 帧的 Promised Stream ID 字段指定了一个预示的新流 (由服务端发起)，

  - 在服务端该新流会由空闲 `idle` 状态进入被保留的 (本地) `reserved(local)` 状态
  - 在客户端该新流会由空闲 `idle` 状态进入被保留的 (远端) `reserved(remote)` 状态

> 在 [3.2 - Starting HTTP/2 for "http" URIs](https://link.juejin.cn?target=https%3A%2F%2Fhttpwg.org%2Fspecs%2Frfc7540.html%23discover-http) 中介绍了一种特殊情况:
>
> > 客户端发起一个 HTTP/1.1 请求，请求带有 Upgrade 机制，想创建 h2c 连接，服务端同意升级返回 101 响应。 升级之前发送的 HTTP/1.1 请求被分配一个流标识符 0x1，并被赋予默认优先级值。从客户端到服务端这个流 1 隐式地转为 "half-closed" 状态，因为作为 HTTP/1.1 请求它已经完成了。HTTP/2 连接开始后，流 1 用于响应。详细过程可以看下文的 [HTTP/2 的协议协商机制](#HTTP-2-的协议协商机制)

此状态下接收到 HEADERS 和 PRIORITY 以外的帧被视为 PROTOCOL_ERROR

状态图中 `send PP` 和 `recv PP` 是指连接的双方端点发送或接收了 PUSH_PROMISE，不是指某个空闲流发送或接收了 PUSH_PROMISE，是 PUSH_PROMISE 的出现促使一个预示的流从 `idle` 状态转为 `reserved`

> 在下文 [Server-Push](#Server-Push) 中会详细介绍服务端推送的内容和 PUSH_PROMISE 的使用情形

**reserved (local) / reserved (remote)**

PUSH_PROMISE 预示的流由 `idle` 状态进入此状态，代表准备进行 Server push

其状态转换:

- PUSH_PROMISE 帧预示的流的响应以 HEADERS 帧开始，这会立即将该流在服务端置于半关闭 (远端) `half-closed(remote)` 状态，在客户端置于半关闭 (本地) `half-closed(local)` 状态，最后以携带 END_STREAM 的帧结束，这会将流置于关闭 `closed` 状态
- 任一端点都可以发送 RST_STREAM 帧来终止这个流，其状态由 `reserved` 转为 `closed`

`reserved(local)` 状态下的流不能发送 HEADERS、RST_STREAM、PRIORITY 以外的帧，接收到 RST_STREAM、PRIORITY、WINDOW_UPDATE 以外的帧被视为 PROTOCOL_ERROR

`reserved(remote)` 状态下的流不能发送 RST_STREAM、WINDOW_UPDATE、PRIORITY 以外的帧，接收到 HEADERS、RST_STREAM、PRIORITY 以外的帧被视为 PROTOCOL_ERROR

**open**

处于 `open` 状态的流可以被两个对端用来发送任何类型的帧

其状态转换:

- 任一端都可以发送带有 END_STREAM 标识的帧，发送方会转入 `half-closed(local)` 状态；接收方会转入 `half-closed(remote)` 状态
- 任一端都可以发送 RST_STREAM 帧，这会使流立即进入 `closed` 状态

**half-closed (local)**

流是双向的，半关闭表示这个流单向关闭了，local 代表本端到对端的方向关闭了，remote 代表对端到本端的方向关闭了

此状态下的流不能发送 WINDOW_UPDATE、PRIORITY、RST_STREAM 以外的帧

当此状态下的流收到带有 END_STREAM 标识的帧或者任一方发送 RST_STREAM 帧，会转为 `closed` 状态

此状态下的流收到的 PRIORITY 帧用以调整流的依赖关系顺序，可以看下文的流优先级

**half-closed (remote)**

此状态下的流不会被对端用于发送帧，执行流量控制的端点不再有义务维护接收方的流控制窗口。

一个端点在此状态的流上接收到 WINDOW_UPDATE、PRIORITY、RST_STREAM 以外的帧，应该响应一个 STREAM_CLOSED 流错误

此状态下的流可以被端点用于发送任意类型的帧，且此状态下该端点仍会观察流级别的流控制的限制

当此状态下的流发送带有 END_STREAM 标识的帧或者任一方发送 RST_STREAM 帧，会转为 `closed` 状态

**closed**

代表流已关闭

此状态下的流不能发送 PRIORITY 以外的帧，发送 PRIORITY 帧是调整那些依赖这个已关闭的流的流优先级，端点都应该处理 PRIORITY 帧，尽管如果该流从依赖关系树中移除了也可以忽略优先级帧

此状态下在收到带有 END_STREAM 标识的 DATA 或 HEADERS 帧后的一小段时间内 (period) 仍可能接收到 WINDOW_UPDATE 或 RST_STREAM 帧，因为在远程对端接收并处理 RST_STREAM 或带有 END_STREAM 标志的帧之前，它可能会发送这些类型的帧。但是端点必须忽略接收到的 WINDOW_UPDATE 或 RST_STREAM

如果一个流发送了 RST_STREAM 帧后转入此状态，而对端接收到 RST_STREAM 帧时可能已经发送了或者处在发送队列中，这些帧是不可撤销的，发送 RST_STREAM 帧的端点必须忽略这些帧。

一个端点可以限制 period 的长短，在 period 内接受的帧会忽略，超出 period 的帧被视为错误。

一个端点发送了 RST_STREAM 帧后接收到流控制帧(比如 DATA)，仍会计入流量窗口，即使这些帧会被忽略，因为对端肯定是在接收到 RST_STREAM 帧前发送的流控制帧，对端会认为流控制已生效

一个端点可能会在发送了 RST_STREAM 帧后收到 PUSH_PROMISE 帧，即便预示的流已经被重置 (reset)，PUSH_PROMISE 帧也能使预示流变成 `reserved` 状态。因此，需要 RST_STREAM 来关闭一个不想要的预示流。

> PRIORITY 帧可以被任意状态的流发送和接收，未知类型的帧会被忽略

**流状态的转换**

下面看两个例子来理解流状态:



![image](https://raw.githubusercontent.com/why862555625/images/main/1658dc4f32767fb6%7Etplv-t2oaga2asx-jj-mark%3A3024%3A0%3A0%3A0%3Aq75.png)



(1)、Server 在 Client 发起的一个流上发送 PUSH_PROMISE 帧，其 Promised Stream ID 指定一个预示流用于后续推送，send PP 后这个预示流在服务端从 idle 状态转为 reserve(local) 状态，客户端 recv PP 后这个流从 idle 状态转为 reserve(remote) 状态

(2)(3)、此时预示流处于保留状态，客户端如果选择拒绝接受推送，可以发送 RST 帧关闭这个流；服务端如果此时出问题了也可以发送 RST 帧取消推送。不管哪一方发送或接收到 RST，此状态都转为 closed

(4)、没有出现重置说明推送仍有效，则服务端开始推送，首先发送的肯定是响应的 HEADERS 首部块，此时流状态转为半关闭 half-closed(remote)；客户端接收到 HEADERS 后流状态转为半关闭 half-closed(local)

(5)(6)、半关闭状态下的流应该还会继续推送诸如 DATA 帧、CONTINUATION 帧这样的数据帧，如果这个过程碰到任一方发起重置，则流会关闭进入 closed 状态

(7)、如果一切顺利，资源随着数据帧响应完毕，最后一帧会带上 END_STREAM 标识代表这个流结束了，此时流转为 closed 状态



![image](https://raw.githubusercontent.com/why862555625/images/main/1658dc4f58e6679e%7Etplv-t2oaga2asx-jj-mark%3A3024%3A0%3A0%3A0%3Aq75.png)



(1)、客户端发起请求，首先发送一个 HEADERS 帧，其 Stream Identifier 创建一个新流，此流从 idle 状态转为 open 状态

(2)(3)、如果客户端取消请求可以发送 RST 帧，服务端出错也可以发送 RST 帧，不管哪一方接收或发送 RST，流关闭进入 closed 状态；

(4)、如果请求结束(END_STREAM)，流转为半关闭状态。假如是 GET 请求，一般 HEADERS 帧就是最后一帧，send H 后流会立即进入半关闭状态。假如是 POST 请求，待数据传完，最后一帧带上 END_STREAM 标识，流转为半关闭

(5)(6)、客户端半关闭后服务端开始返回响应，此时任一方接收或发送 RST，流关闭；

(7)、如果一切顺利，等待响应结束(END_STREAM)，流关闭

**流的标识符**

流 ID 是 31 位无符号整数，客户端发起的流必须是奇数，服务端发起的流必须是偶数，0x0 保留为连接控制消息不能用于建立新流。

HTTP/1.1 Upgrade to HTTP/2 时响应的流 ID 是 0x1，在升级完成之后，流 0x1 在客户端会转为 `half-closed (local)` 状态，因此这种情况下客户端不能用 0x1 初始化一个流

新建立的流的 ID 必须大于所有已使用过的数字，接收到一个错误大小的 ID 应该返回 PROTOCOL_ERROR 响应

使用一个新流时隐式地关闭了对端发起的 ID 小于当前流的且处于 `idle` 状态的流，比如一个流发送一个 HEADERS 帧打开了 ID 为 7 的流，但还从未向 ID 为 5 的流发送过帧，则流 0x5 会在 0x7 发送完或接收完第一帧后转为 `closed` 状态

一个连接内的流 ID 不能重用

**流的优先级**

客户端可以通过 HEADERS 帧的 PRIORITY 信息指定一个新建立流的优先级，其他期间也可以发送 PRIORITY 帧调整流优先级

设置优先级的目的是为了让端点表达它所期望对端在并发的多个流之间如何分配资源的行为。更重要的是，当发送容量有限时，可以使用优先级来选择用于发送帧的流。

流可以被标记为依赖其他流，所依赖的流完成后再处理当前流。每个依赖 (dependency) 后都跟着一个权重 (weight)，这一数字是用来确定依赖于相同的流的可分配可用资源的相对比例

**流依赖(Stream Dependencies)**

每个流都可以显示地依赖另一个流，包含依赖关系表示优先将资源分配给指定的流(上层节点)而不是依赖流

一个不依赖于其他流的流会指定 stream dependency 为 0x0 值，因为不存在的 0x0 流代表依赖树的根

一个依赖于其他流的流叫做**依赖流**，被依赖的流是当前流的父级。如果被依赖的流不在当前依赖树中(比如状态为 `idle` 的流)，被依赖的流会使用一个默认优先级

当依赖一个流时，该流会添加进父级的依赖关系中，共享相同父级的依赖流不会相对于彼此进行排序，比如 B 和 C 依赖 A，新添加一个依赖流 D，BCD 的顺序是不固定的:

```
    A                 A
   / \      ==>      /|\
  B   C             B D C
```

独占标识 (exclusive) 允许插入一个新层级(新的依赖关系)，独占标识导致该流成为父级的唯一依赖流，而其他依赖流变为其子级，比如同样插入一个新依赖流 E (带有 exclusive):

```
                      A
    A                 |
   /|\      ==>       E
  B D C              /|\
                    B D C
```

在依赖关系树中，只有当一个依赖流所依赖的所有流(父级最高为 0x0 的链)被关闭或者无法继续在上面执行，这个依赖流才应该被分配资源

**依赖权重**

所有依赖流都会分配一个 1~256 权重值

相同父级的依赖流按权重比例分配资源，比如流 B 依赖于 A 且权重值为 4，流 C 依赖于 A 且权重值为 12，当 A 不再执行时，B 理论上能分配的资源只有 C 的三分之一

**优先级调整 (Reprioritization)**

使用 PRIORITY 帧可以调整流优先级

PRIORITY 帧内容与 HEADERS 帧的优先级模块相同:

```
 +-+-------------------------------------------------------------+
 |E|                  Stream Dependency (31)                     |
 +-+-------------+-----------------------------------------------+
 |   Weight (8)  |
 +-+-------------+
```

- 如果父级重新设置了优先级，则依赖流会随其父级流一起移动。若调整优先级的流带有独占标识，会导致新的父流的所有子级依赖于这个流
- 如果一个流调整为依赖自己的一个子级，则这个将被依赖的子级首先移至调整流的父级之下(即同一层)，再移动那个调整流的整棵子树，移动的依赖关系保持其权重

看下面这个例子: 第一个图是初始关系树，现在 A 要调整为依赖 D，根据第二点，现将 D 移至 x 之下，再把 A 调整为 D 的子树(图 3)，如果 A 调整时带有独占标识根据第一点 F 也归为 A 子级(图 4)

```
    x                x                x                 x
    |               / \               |                 |
    A              D   A              D                 D
   / \            /   / \            / \                |
  B   C     ==>  F   B   C   ==>    F   A       OR      A
     / \                 |             / \             /|\
    D   E                E            B   C           B C F
    |                                     |             |
    F                                     E             E
               (intermediate)   (non-exclusive)    (exclusive)
```

**流优先级的状态管理**

当一个流从依赖树中移除，它的子级可以调整为依赖被关闭流的父级(应该就是连接上一层节点)，新的依赖权重将根据关闭流的权重以及流自身的权重重新计算。

从依赖树中移除流会导致某些优先级信息丢失。资源在具有相同父级的流之间共享，这意味着如果这个集合中的某个流关闭或者阻塞，任何空闲容量将分配给最近的相邻流。然而，如果此集合的共有依赖(即父级节点)从树中移除，这些子流将与更上一层的流共享资源

一个例子: 流 A 和流 B 依赖相同父级节点，而流 C 和流 D 都依赖 A，在移除流 A 之前的一段时间内，A 和 D 都无法执行(可能任务阻塞了)，则 C 会分配到 A 的所有资源； 如果 A 被移除出树了，A 的权重按比重新计算分配给 C 和 D，此时 D 仍旧阻塞，C 分配的资源相较之前变少了。对于同等的初始权重，C 获取到的可用资源是三分之一而不是二分之一(为什么是三分之一?文档中没有说明细节，权重如何重新分配也不太清楚，下面是按我的理解解释的)

X 的资源为 1，ABCD 初始权重均为 16，*号代表节点当前不可用，图一中 C 和 B 各占一半资源，而 A 移除后 CD 的权重重新分配变为 8，所以图二中 C 和 B 占比变为 1:2，R(C) 变为 1/3

```
         X(v:1.0)               X(v:1.0)
         / \                    /|\
        /   \                  / | \
      *A     B       ==>      /  |  \
    (w:16) (w:16)            /   |   \
      / \                   C   *D    B
     /   \                (w:8)(w:8)(w:16)
    C    *D
 (w:16) (w:16)


 R(C)=16/(16+16)=1/2 ==>  R(C)=8/(8+16)=1/3
```

可能向一个流创建依赖关系的优先级信息还在传输中，那个流就已经关闭了。如果一个依赖流的依赖指向没有相关优先级信息(即父节点无效)，则这个依赖流会分配默认优先级，这可能会造成不理想的优先级，因为给流分配了不在预期的优先级。

为了避免上述问题，一个端点应该在流关闭后的一段时间内保留流的优先级调整状态信息，此状态保留时间越长，流被分配错误的或者默认的优先级可能性越低。

类似地，处于“空闲”状态的流可以被分配优先级或成为其他流的父节点。这允许在依赖关系树中创建分组节点，从而实现更灵活的优先级表达式。空闲流以默认优先级开始

流优先级状态信息的保留可能增加终端的负担，因此这种状态可以被限制。终端可能根据负荷来决定保留的额外的状态的数目；在高负荷下，可以丢弃额外的优先级状态来限制资源的任务。在极端情况下，终端甚至可以丢弃激活或者保留状态流的优先级信息。如果使用了固定的限制，终端应当至少保留跟 SETTINGS_MAX_CONCURRENT_STREAMS 设置一样大小的流状态

**默认优先级**

所有流都是初始为非独占地依赖于流 0x0。

Pushed 流初始依赖于相关的流(见 Server-Push)。

以上两种情况，流的权重都指定为 16。



### 3. 服务端推送 (Server Push)

浏览器发送一个请求，服务器主动向浏览器推送与这个请求相关的资源，这样浏览器就不用发起后续请求。

Server-Push 主要是针对资源内联做出的优化，相较于 http/1.1 资源内联的优势:

- 客户端可以缓存推送的资源
- 客户端可以拒收推送过来的资源
- 推送资源可以由不同页面共享
- 服务器可以按照优先级推送资源

##### Server Push详解（选读）

**PUSH_PROMISE 帧格式**

```
+---------------+
 |Pad Length? (8)|
 +-+-------------+-----------------------------------------------+
 |R|                  Promised Stream ID (31)                    |
 +-+-----------------------------+-------------------------------+
 |                   Header Block Fragment (*)                 ...
 +---------------------------------------------------------------+
 |                           Padding (*)                       ...
 +---------------------------------------------------------------+
```

> - `Pad Length`: 指定 Padding 长度，存在则代表 PADDING flag 被设置
> - `R`: 保留的1bit位
> - `Promised Stream ID`: 31 位的无符号整数，代表 PUSH_PROMISE 帧保留的流，对于发送者来说该流标识符必须是可用于下一个流的有效值
> - `Header Block Fragment`: 包含请求首部域的首部块片段
> - `Padding`: 填充字节，没有具体语义，作用与 DATA 的 Padding 一样，存在则代表 PADDING flag 被设置

PUSH_PROMISE 帧有以下标识 (flags):

> - END_HEADERS: bit 2 置 1 代表 header 块结束
> - PADDED: bit 3 置 1 代表 Pad 被设置，存在 Pad Length 和 Padding

**Push 的过程**

结合上文关于 Server-Push 的流状态转换

PUSH_PROMISE 帧只能在对端(客户端)发起的且流状态为 open 或者 half-closed (remote) 的流上发送

PUSH_PROMISE 帧准备推送的响应总是和来自于客户端的请求相关联。服务端在该请求所在的流上发送 PUSH_PROMISE 帧。PUSH_PROMISE 帧包含一个 Promised Stream ID，该流标识符是从服务端可用的流标识符里选出来的。

如果服务端收到了一个对文档的请求，该文档包含内嵌的指向多个图片文件的链接，且服务端选择向客户端推送那些额外的图片，那么在发送包含图片链接的 DATA 帧之前发送 PUSH_PROMISE 帧可以确保客户端在发现内嵌的链接之前，能够知道有一个资源将要被推送过来。同样地，如果服务端准备推送被首部块引用的响应 (比如，在 [Link 首部字段](https://link.juejin.cn?target=https%3A%2F%2Fwww.w3.org%2Fwiki%2FLinkHeader) 里的)，在发送首部块之前发送一个 PUSH_PROMISE 帧，可以确保客户端不再请求那些资源

一旦客户端收到了 PUSH_PROMISE 帧，并选择接收被推送的响应，客户端就不应该为准备推送的响应发起任何请求，直到预示的流被关闭以后。



![image](https://raw.githubusercontent.com/why862555625/images/main/1658dc4fef38d8bd%7Etplv-t2oaga2asx-jj-mark%3A3024%3A0%3A0%3A0%3Aq75.png)

![image](https://raw.githubusercontent.com/why862555625/images/main/1658dc5033242dae%7Etplv-t2oaga2asx-jj-mark%3A3024%3A0%3A0%3A0%3Aq75.png)



> 注意图中推送的四个资源各预示了一个流 (Promised Stream ID)，而发送 PUSH_PROMISE 帧的还是在客户端发起的请求流 (Stream Identifier = 1) 上，客户端收到 PUSH_PROMISE 帧并选择接收便不会对这四个资源发起请求，之后服务端会发起预示的流然后推送资源相关的响应

不管出于什么原因，如果客户端决定不再从服务端接收准备推送的响应，或者如果服务端花费了太长时间准备发送被预示的响应，客户端可以发送一个 RST_STREAM 帧，该帧可以使用 CANCEL 或者 REFUSED_STEAM 码，并引用被推送的流标识符。

**nginx 配置 Server-Push**

> server-push 需要服务端设置，并不是说浏览器发起请求，与此请求相关的资源服务端就会自动推送

以 nginx 为例，从版本 1.13.9 开始正式支持 hppt2 serverpush 功能，

在相应 server 或 location 模块中加入 `http2_push` 字段加上相对路径的文件即可在请求该资源时推送相关资源，比如我的博客设置如下，访问首页时有四个文件会由服务器主动推送过去而不需要客户端请求:

```
复制代码  server_name  blog.wangriyu.wang;
  root /blog;
  index index.html index.htm;

  location = /index.html {
    http2_push /css/style.css;
    http2_push /js/main.js;
    http2_push /img/yule.jpg;
    http2_push /img/avatar.jpg;
  }
```

通过浏览器控制台可以查看 `Push` 响应:



![image](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/8/31/1658dc510af263a8~tplv-t2oaga2asx-jj-mark:3024:0:0:0:q75.png)



也可以用 `nghttp` 测试 push 响应 (* 号代表是服务端推送的):



![image](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2018/8/31/1658dc4fa7d18e24~tplv-t2oaga2asx-jj-mark:3024:0:0:0:q75.png)



上面 `http2_push` 的设置适合静态资源，服务端事先知道哪些文件是客户端需要的，然后选择性推送

假如是后台应用动态生成的文件(比如 json 文件)，服务器事先不知道要推送什么，可以用 `Link` 响应头来做自动推送

在 server 模块中添加 `http2_push_preload on;`

```
server_name  blog.wangriyu.wang;
  root /blog;
  index index.html index.htm;

  http2_push_preload on;
```

然后设置响应头 (add_header) 或者后台程序生成数据文件返回时带上响应头 Link 标签，比如

```
Link: </style.css>; as=style; rel=preload, </main.js>; as=script; rel=preload, </image.jpg>; as=image; rel=preload
```

nginx 会根据 Link 响应头主动推送这些资源




### 4. 请求优先级设置

HTTP/2 里的每个 stream 都可以设置依赖 (Dependency) 和权重，可以按依赖树分配优先级，解决了关键请求被阻塞的问题

### 5. 流量控制

HTTP/2 使用流量控制（Flow Control）来确保在网络连接上传输的数据量不超出接收端的处理能力。流量控制的主要目标是防止发送者发送过多的数据，导致接收者无法及时处理，从而引发拥塞或性能下降。HTTP/2 中的流量控制是基于帧（Frames）的，每个流（Stream）都有一个关联的流量控制窗口（Flow Control Window）。



> 以下是 HTTP/2 中流量控制的基本原理和机制：
>
> 1. **流量控制窗口：** 每个流都有一个流量控制窗口，用于表示该流上可以发送的数据量。初始时，流量控制窗口的大小是由 SETTINGS 帧中的初始窗口大小（Initial Window Size）指定的。接收方会定期向发送方发送 WINDOW_UPDATE 帧来扩大流量控制窗口的大小，通知发送方可以发送更多的数据。
> 2. **连接级流量控制：** HTTP/2 还定义了连接级的流量控制窗口，它用于限制整个连接上的数据流量。连接级窗口的大小也是由 SETTINGS 帧中的初始窗口大小指定，并可以通过 WINDOW_UPDATE 帧来调整。
> 3. **帧的流量控制：** 每个 DATA 帧（携带请求和响应的主体数据）都有一个与之关联的流量控制窗口。发送方必须确保发送的 DATA 帧的大小不超过流量控制窗口的大小，接收方在接收到 DATA 帧后，会相应地减小流量控制窗口的大小。
> 4. **WINDOW_UPDATE 帧：** 发送方可以发送 WINDOW_UPDATE 帧，来通知接收方可以扩大流量控制窗口的大小。WINDOW_UPDATE 帧携带了增加的窗口大小，可以是流量控制窗口或者连接级窗口的增量。



通过以上机制，HTTP/2 中的流量控制确保了数据的有序传输，并防止了发送过多数据导致接收方无法处理的情况。流量控制的灵活性和精细度使得 HTTP/2 能够更好地适应不同网络条件和接收方处理能力，提高了网络性能和用户体验。

### 6. 应用层的重置连接

对于 HTTP/1 来说，是通过设置 tcp segment 里的 reset flag 来通知对端关闭连接的。这种方式会直接断开连接，下次再发请求就必须重新建立连接。HTTP/2 引入 RST_STREAM 类型的 frame，可以在不断开连接的前提下取消某个 request 的 stream，表现更好。

### 7. HTTP/1 的几种优化可以弃用

1、域名分片

HTTP/2 对于同一域名使用一个 TCP 连接足矣，过多 TCP 连接浪费资源而且效果不见得一定好

而且资源分域会破坏 HTTP/2 的优先级特性，还会降低头部压缩效果

2、资源合并

资源合并会不利于缓存机制，而且单文件过大对于 HTTP/2 的传输不好，尽量做到细粒化更有利于 HTTP/2 传输

3、资源内联

HTTP/2 支持 Server-Push，相比较内联优势更大效果更好

而且内联的资源不能有效缓存

如果有共用，多页面内联也会造成浪费



## 升级HTTP/2的优劣

## 劣

升级到HTTP/2并不是一种适用于所有情况的通用解决方案。虽然HTTP/2在许多方面都提供了性能优势，但也有一些特定的情况，可能不适合升级到HTTP/2，或者需要谨慎考虑：

1. **老旧的服务器和客户端：** 一些老旧的服务器软件和客户端应用程序可能不支持HTTP/2协议。在这种情况下，升级可能会引发兼容性问题。
2. **简单的静态网站：** 如果网站内容非常简单，主要由静态文件组成，并且对性能要求不高，升级到HTTP/2的收益可能较小。HTTP/1.1对于简单的静态网站来说通常足够了。
3. **资源优化不足：** 如果网站的性能问题主要源于资源优化不足，例如未压缩的图片、未合并的脚本和样式表等，那么升级到HTTP/2并不会根本解决这些问题。在升级之前，应该先优化网站的资源。
4. **服务器性能限制：** 如果服务器的性能受限，无法处理大量的并发请求，那么HTTP/2的多路复用特性可能会导致服务器过载，反而降低性能。
5. **特殊网络环境：** 在某些网络环境下，例如高延迟、高丢包率的网络，HTTP/2的多路复用特性可能会导致丢失的数据包需要重新传输，从而增加了网络负担。
6. **过于复杂的配置：** 如果HTTP/2的配置比较复杂，或者在现有的基础设施中引入HTTP/2会带来很大的复杂性，那么在考虑升级时需要慎重评估成本和收益。

在决定是否升级到HTTP/2时，需要综合考虑网站的性能需求、服务器和客户端的兼容性、网络环境以及现有基础设施的情况。在一些特定场景下，HTTP/1.1仍然可能是一个合适的选择。



什么时候HTTP/2会比HTTP1.1慢

> 1. **小文件的传输：** 当需要传输大量非常小的文件时（1k<），HTTP/2 的多路复用机制可能会导致头部信息在传输中占用较大比例，从而增加了总体的传输量。在这种情况下，HTTP/1.1 的多个并行连接可能更加高效。
> 2. **连接复用受限：** 在某些网络环境下，连接的复用可能受到限制，例如高延迟、高丢包率的网络。在这种情况下，HTTP/2 的连接复用特性可能会受到影响，甚至导致性能下降。
> 3. **服务器性能不足：** 如果服务器性能不足以处理大量并发的请求，HTTP/2 的多路复用可能导致服务器过载，从而增加了响应时间。HTTP/1.1 的多个连接可能分散了请求，减轻了服务器的负担。
> 4. **头部压缩开销：** HTTP/2 使用 HPACK 算法对头部信息进行压缩，但解压缩头部信息也需要计算资源。在某些情况下，特别是在移动设备上，解压缩可能会增加处理的复杂性和开销。
> 5. **代理服务器和防火墙限制：** 一些代理服务器和防火墙可能不正确地处理或者不支持HTTP/2，导致在这些设备上的传输性能下降。

## 优

1. **提高网站性能**：HTTP/2引入了多路复用（Multiplexing）功能，可以同时传输多个请求和响应，减少了网络延迟，提高了网站加载速度。如果您的网站有很多资源（例如图片、样式表、脚本等），并且希望提供更快的加载时间，升级到HTTP/2可能是一个不错的选择。
2. **支持移动设备**：HTTP/2对于移动设备的性能优化效果显著。移动网络通常具有较高的延迟，HTTP/2的多路复用特性能够更好地利用网络带宽，提供更快的加载速度，从而提高了移动设备用户的体验。
3. **提高SEO排名**：Google已经确认，网站加载速度是搜索引擎排名的一个因素。更快的网站加载速度可能对SEO产生积极影响，因此，如果您关注网站的搜索引擎可见性，升级到HTTP/2可能是一个好的策略。
4. **支持新的Web功能**：一些现代的Web功能，例如服务端推送（Server Push），在HTTP/2中得到了良好的支持。如果您计划使用这些新功能，升级到HTTP/2是必要的。
5. **提供更好的安全性**：HTTP/2通常与TLS（HTTPS）一起使用，因此可以提供更好的数据安全性。如果您的网站处理用户敏感信息，使用HTTPS和HTTP/2可以增加数据传输的安全性。



# 升级方案

目前我们网站的运行流程：

![image-20231008154140054](https://raw.githubusercontent.com/why862555625/images/main/image-20231008154140054.png)

## 1. 哪些NG需要升级？

**前端静态资源托管NG，目前前端首页资源请求超过160个,适合升级成http/2**

![image-20231008155549620](https://raw.githubusercontent.com/why862555625/images/main/image-20231008155549620.png)

**图片服务请求数量超30，适合升级成http/2**

![image-20231008160102350](https://raw.githubusercontent.com/why862555625/images/main/image-20231008160102350.png)

后端请求较少，只有9个可以选择不升级

![image-20231008160230467](https://raw.githubusercontent.com/why862555625/images/main/image-20231008160230467.png)

## 2. 怎么升级

### 前端静态资源托管NG升级HTTP/2

要将Chrome浏览器的网站请求改为使用HTTP/2，需要确保网站支持HTTP/2，并且浏览器和服务器之间的连接是安全的（即使用HTTPS协议）。HTTP/2通常与TLS（Transport Layer Security）一起使用，以确保数据的安全传输。

以下是确保Chrome浏览器请求网站使用HTTP/2的步骤：

1. **确保您的网站支持HTTP/2**：在服务器端配置中启用HTTP/2。大多数现代的Web服务器（例如Apache、Nginx）已经支持HTTP/2。请参考您所使用服务器的文档，以了解如何启用HTTP/2。

2. **使用HTTPS协议**：HTTP/2通常与TLS（即HTTPS）一起使用。要启用HTTP/2，您的网站必须使用安全套接字层（SSL/TLS）加密。您需要在服务器上配置SSL证书。您可以从证书颁发机构（CA）获取SSL证书，或者使用免费的证书颁发机构，例如Let's Encrypt。

3. **配置服务器**：

   ```nginx
   vbnetCopy codeserver {
       listen 443 ssl http2;
       ssl_certificate /path/to/your/certificate.crt;
       ssl_certificate_key /path/to/your/private.key;
       ...
   }
   ```

4. **验证设置**：确保服务器已经配置正确，并且网站可以通过HTTPS访问。您可以使用在线工具，例如[SSL Labs](https://www.ssllabs.com/ssltest/)，来检查您的SSL/TLS配置。

一旦您的网站已经配置为支持HTTP/2并且可以通过HTTPS访问，当用户使用Chrome浏览器访问该网站时，浏览器会自动使用HTTP/2进行请求。Chrome会自动选择使用最新的协议版本，而无需手动配置。Chrome会根据标准的协议选择HTTP/2来提高网站性能。

## 阿里图库升级HTTP2

https://help.aliyun.com/document_detail/65103.html
